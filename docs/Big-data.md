# Big data project 

### Big data anaylytics with Java 
+ Example : log file(structured/ unstructured)
+ Big data storage 
+ ETL like world - big data stack 
+ Run big data in batch mode in parallel or with several machine  - or using Map Reduce program 
+ Batch computation - Apache Spark
+ Big data stack : Apache Spark, Hive, Hadoop, HDFS 
+ Spark API core
+ Spark packages  
+ Data compression format : Avro, Parquet 
+ Streaming data, predictive analytics,logs file, web access logs, 
+ 
+ 


### Hadoop ecosystem :
+ HDFS, Spark, MapReduce,Solr,Hive
+ Distributed computing env 
+ Computing jobs 
+ Master - slave architecture 
+ Analytics : Impala,Spark ,
+ Batch : MapReduce, Hive, Pig 
+ Stream data : Spark , Storm 
+ Machine learning : SparkML , Mahout
+ NoSQL : HBase, Solr(Search)
+ HDFS : storage 
+ Yarn : cluster resource management 
+ 


### Example use case 
+ Batch product : batch processing, MapReduce, parallel computing batch framework 
+ Real time analytics : Spark, Storm 
+ Search : HDFS storage with pdf format, text format, index text format, solr, 
+ NoSQL: Cassandra, HBase  
+ Machine learning lib : Clustering computing framework, SparkML, Apache Spark ships Apache Mahout,






### Apache Flink versus Spark 
+ Spark streaming : stream-batching operations - micro batching - credit card fraud detection 
+ Flink : fraud detection 

### Real time data streaming frameworks 
+ Kafka stream API 
    + stateless processing - filter and mapping 
    + kubernetes container - 
    + spark streaming : 