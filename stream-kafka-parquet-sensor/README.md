# Writing Streaming Data to Parquet
- data : sensorId, a timestamp, and a value
-  Streaming Context:
- Schema class : SensorData 
- Loading and reloading data at rest to enrich our streaming data
- join data with different join modes
- Spark Streaming scheduler

- Spark SQL
    - write access to structured data 


- Data to stream : 10K sensors 

- long-lived processes like a Spark Streaming job


- Join optimization 



# how to run 
- pip3 install jep jedi pyspark virtualenv
- https://github.com/polynote/polynote/releases




# sample ref data 
<a href="https://imgur.com/NpET70l"><img src="https://i.imgur.com/NpET70l.png" title="source: imgur.com" /></a>


# Updating Reference Datasets in a Streaming Application
