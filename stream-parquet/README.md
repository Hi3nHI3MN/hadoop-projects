# Writing Streaming Data to Parquet
- data : sensorId, a timestamp, and a value
-  Streaming Context:
- Schema class : SensorData 
- Loading and reloading data at rest to enrich our streaming data
- join data with different join modes
- Spark Streaming scheduler

- Spark SQL
    - write access to structured data 


- Data to stream : 10K sensors 

- long-lived processes like a Spark Streaming job


# how to run 
- pip3 install jep jedi pyspark virtualenv
- https://github.com/polynote/polynote/releases
